{"cells":[{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: dcor in c:\\users\\sonia\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.6)\n","Requirement already satisfied: numpy in c:\\users\\sonia\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dcor) (2.0.1)\n","Requirement already satisfied: numba>=0.51 in c:\\users\\sonia\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dcor) (0.60.0)\n","Requirement already satisfied: scipy in c:\\users\\sonia\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dcor) (1.14.0)\n","Requirement already satisfied: joblib in c:\\users\\sonia\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dcor) (1.4.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\sonia\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba>=0.51->dcor) (0.43.0)\n","Requirement already satisfied: xgboost in c:\\users\\sonia\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.1)\n","Requirement already satisfied: numpy in c:\\users\\sonia\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (2.0.1)\n","Requirement already satisfied: scipy in c:\\users\\sonia\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.14.0)\n"]}],"source":["!pip install dcor\n","# !pip install numpy==1.20.3\n","# !pip install hdbscan==0.8.33\n","!pip install xgboost"]},{"cell_type":"code","execution_count":24,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-07T06:49:04.258757Z","iopub.status.busy":"2024-08-07T06:49:04.257724Z","iopub.status.idle":"2024-08-07T06:49:04.787324Z","shell.execute_reply":"2024-08-07T06:49:04.786095Z","shell.execute_reply.started":"2024-08-07T06:49:04.258696Z"},"trusted":true},"outputs":[],"source":["# # This Python 3 environment comes with many helpful analytics libraries installed\n","# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# # For example, here's several helpful packages to load\n","\n","# import numpy as np # linear algebra\n","# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# # Input data files are available in the read-only \"../input/\" directory\n","# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:49:04.794616Z","iopub.status.busy":"2024-08-07T06:49:04.794018Z","iopub.status.idle":"2024-08-07T06:49:05.960562Z","shell.execute_reply":"2024-08-07T06:49:05.958772Z","shell.execute_reply.started":"2024-08-07T06:49:04.794571Z"},"trusted":true},"outputs":[],"source":["# !cd /kaggle/working"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:49:05.963662Z","iopub.status.busy":"2024-08-07T06:49:05.963218Z","iopub.status.idle":"2024-08-07T06:49:05.972596Z","shell.execute_reply":"2024-08-07T06:49:05.970837Z","shell.execute_reply.started":"2024-08-07T06:49:05.963622Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","pd.set_option('display.max_columns' , None)\n","pd.set_option('display.max_rows' , None)\n","pd.set_option('display.max_colwidth' , None)\n","pd.set_option('max_info_columns' , -1)\n","pd.set_option('max_info_rows' , -1)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:49:05.978145Z","iopub.status.busy":"2024-08-07T06:49:05.977614Z","iopub.status.idle":"2024-08-07T06:49:06.045105Z","shell.execute_reply":"2024-08-07T06:49:06.043690Z","shell.execute_reply.started":"2024-08-07T06:49:05.978100Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                  Name     Sex   Age  SibSp  \\\n","0                              Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n","2                               Heikkinen, Miss. Laina  female  26.0      0   \n","3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                             Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["orig_df = pd.read_csv(\"train.csv\")\n","orig_df.head()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:49:06.048271Z","iopub.status.busy":"2024-08-07T06:49:06.046643Z","iopub.status.idle":"2024-08-07T06:49:06.055919Z","shell.execute_reply":"2024-08-07T06:49:06.054216Z","shell.execute_reply.started":"2024-08-07T06:49:06.048198Z"},"trusted":true},"outputs":[],"source":["df = orig_df.copy()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:49:06.058870Z","iopub.status.busy":"2024-08-07T06:49:06.058270Z","iopub.status.idle":"2024-08-07T06:49:06.103166Z","shell.execute_reply":"2024-08-07T06:49:06.101889Z","shell.execute_reply.started":"2024-08-07T06:49:06.058811Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 418 entries, 0 to 417\n","Data columns (total 11 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  418 non-null    int64  \n"," 1   Pclass       418 non-null    int64  \n"," 2   Name         418 non-null    object \n"," 3   Sex          418 non-null    object \n"," 4   Age          332 non-null    float64\n"," 5   SibSp        418 non-null    int64  \n"," 6   Parch        418 non-null    int64  \n"," 7   Ticket       418 non-null    object \n"," 8   Fare         417 non-null    float64\n"," 9   Cabin        91 non-null     object \n"," 10  Embarked     418 non-null    object \n","dtypes: float64(2), int64(4), object(5)\n","memory usage: 36.1+ KB\n"]}],"source":["test = pd.read_csv(\"test.csv\")\n","test.info(verbose=True, show_counts=True)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:49:06.105170Z","iopub.status.busy":"2024-08-07T06:49:06.104809Z","iopub.status.idle":"2024-08-07T06:49:06.119307Z","shell.execute_reply":"2024-08-07T06:49:06.118046Z","shell.execute_reply.started":"2024-08-07T06:49:06.105138Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 12 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  891 non-null    int64  \n"," 1   Survived     891 non-null    int64  \n"," 2   Pclass       891 non-null    int64  \n"," 3   Name         891 non-null    object \n"," 4   Sex          891 non-null    object \n"," 5   Age          714 non-null    float64\n"," 6   SibSp        891 non-null    int64  \n"," 7   Parch        891 non-null    int64  \n"," 8   Ticket       891 non-null    object \n"," 9   Fare         891 non-null    float64\n"," 10  Cabin        204 non-null    object \n"," 11  Embarked     889 non-null    object \n","dtypes: float64(2), int64(5), object(5)\n","memory usage: 83.7+ KB\n"]}],"source":["df.info(verbose=True, show_counts=True)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:49:06.121378Z","iopub.status.busy":"2024-08-07T06:49:06.120990Z","iopub.status.idle":"2024-08-07T06:49:06.135919Z","shell.execute_reply":"2024-08-07T06:49:06.134600Z","shell.execute_reply.started":"2024-08-07T06:49:06.121346Z"},"trusted":true},"outputs":[{"data":{"text/plain":["681"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["df[\"Ticket\"].nunique()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:49:06.138731Z","iopub.status.busy":"2024-08-07T06:49:06.138159Z","iopub.status.idle":"2024-08-07T06:49:06.153324Z","shell.execute_reply":"2024-08-07T06:49:06.151817Z","shell.execute_reply.started":"2024-08-07T06:49:06.138680Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Embarked\n","S      644\n","C      168\n","Q       77\n","NaN      2\n","Name: count, dtype: int64"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["df[\"Embarked\"].value_counts(dropna=False)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:49:06.155932Z","iopub.status.busy":"2024-08-07T06:49:06.155404Z","iopub.status.idle":"2024-08-07T06:49:06.174719Z","shell.execute_reply":"2024-08-07T06:49:06.172943Z","shell.execute_reply.started":"2024-08-07T06:49:06.155886Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Embarked\n","S    644\n","C    168\n","Q     77\n","Name: count, dtype: int64"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["df = df[df[\"Embarked\"].notnull()].reset_index(drop=True)\n","df[\"Embarked\"].value_counts(dropna=False)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:49:06.177179Z","iopub.status.busy":"2024-08-07T06:49:06.176652Z","iopub.status.idle":"2024-08-07T06:49:06.201411Z","shell.execute_reply":"2024-08-07T06:49:06.199652Z","shell.execute_reply.started":"2024-08-07T06:49:06.177132Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>PassengerId</th>\n","      <td>1.000000</td>\n","      <td>-0.005028</td>\n","      <td>-0.035330</td>\n","      <td>0.033681</td>\n","      <td>-0.057686</td>\n","      <td>-0.001657</td>\n","      <td>0.012703</td>\n","    </tr>\n","    <tr>\n","      <th>Survived</th>\n","      <td>-0.005028</td>\n","      <td>1.000000</td>\n","      <td>-0.335549</td>\n","      <td>-0.082446</td>\n","      <td>-0.034040</td>\n","      <td>0.083151</td>\n","      <td>0.255290</td>\n","    </tr>\n","    <tr>\n","      <th>Pclass</th>\n","      <td>-0.035330</td>\n","      <td>-0.335549</td>\n","      <td>1.000000</td>\n","      <td>-0.365902</td>\n","      <td>0.081656</td>\n","      <td>0.016824</td>\n","      <td>-0.548193</td>\n","    </tr>\n","    <tr>\n","      <th>Age</th>\n","      <td>0.033681</td>\n","      <td>-0.082446</td>\n","      <td>-0.365902</td>\n","      <td>1.000000</td>\n","      <td>-0.307351</td>\n","      <td>-0.187896</td>\n","      <td>0.093143</td>\n","    </tr>\n","    <tr>\n","      <th>SibSp</th>\n","      <td>-0.057686</td>\n","      <td>-0.034040</td>\n","      <td>0.081656</td>\n","      <td>-0.307351</td>\n","      <td>1.000000</td>\n","      <td>0.414542</td>\n","      <td>0.160887</td>\n","    </tr>\n","    <tr>\n","      <th>Parch</th>\n","      <td>-0.001657</td>\n","      <td>0.083151</td>\n","      <td>0.016824</td>\n","      <td>-0.187896</td>\n","      <td>0.414542</td>\n","      <td>1.000000</td>\n","      <td>0.217532</td>\n","    </tr>\n","    <tr>\n","      <th>Fare</th>\n","      <td>0.012703</td>\n","      <td>0.255290</td>\n","      <td>-0.548193</td>\n","      <td>0.093143</td>\n","      <td>0.160887</td>\n","      <td>0.217532</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n","PassengerId     1.000000 -0.005028 -0.035330  0.033681 -0.057686 -0.001657   \n","Survived       -0.005028  1.000000 -0.335549 -0.082446 -0.034040  0.083151   \n","Pclass         -0.035330 -0.335549  1.000000 -0.365902  0.081656  0.016824   \n","Age             0.033681 -0.082446 -0.365902  1.000000 -0.307351 -0.187896   \n","SibSp          -0.057686 -0.034040  0.081656 -0.307351  1.000000  0.414542   \n","Parch          -0.001657  0.083151  0.016824 -0.187896  0.414542  1.000000   \n","Fare            0.012703  0.255290 -0.548193  0.093143  0.160887  0.217532   \n","\n","                 Fare  \n","PassengerId  0.012703  \n","Survived     0.255290  \n","Pclass      -0.548193  \n","Age          0.093143  \n","SibSp        0.160887  \n","Parch        0.217532  \n","Fare         1.000000  "]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["df.corr(numeric_only=True)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:49:24.534633Z","iopub.status.busy":"2024-08-07T06:49:24.533534Z","iopub.status.idle":"2024-08-07T06:50:24.066596Z","shell.execute_reply":"2024-08-07T06:50:24.064939Z","shell.execute_reply.started":"2024-08-07T06:49:24.534581Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\sonia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dcor\\_fast_dcov_avl.py:554: UserWarning: Falling back to uncompiled AVL fast distance covariance terms because of TypeError exception raised: No matching definition for argument type(s) array(int64, 1d, C), array(int64, 1d, C), bool. Rembember: only floating point values can be used in the compiled implementations.\n","  warnings.warn(\n","c:\\Users\\sonia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dcor\\_fast_dcov_avl.py:554: UserWarning: Falling back to uncompiled AVL fast distance covariance terms because of TypeError exception raised: No matching definition for argument type(s) array(int64, 1d, C), array(float64, 1d, C), bool. Rembember: only floating point values can be used in the compiled implementations.\n","  warnings.warn(\n","c:\\Users\\sonia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dcor\\_fast_dcov_avl.py:554: UserWarning: Falling back to uncompiled AVL fast distance covariance terms because of TypeError exception raised: No matching definition for argument type(s) array(float64, 1d, C), array(int64, 1d, C), bool. Rembember: only floating point values can be used in the compiled implementations.\n","  warnings.warn(\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PassengerId</td>\n","      <td>1.000000</td>\n","      <td>0.034880</td>\n","      <td>0.053387</td>\n","      <td>NaN</td>\n","      <td>0.071281</td>\n","      <td>0.029656</td>\n","      <td>0.050245</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Survived</td>\n","      <td>0.034880</td>\n","      <td>1.000000</td>\n","      <td>0.332808</td>\n","      <td>NaN</td>\n","      <td>0.128369</td>\n","      <td>0.136084</td>\n","      <td>0.298424</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Pclass</td>\n","      <td>0.053387</td>\n","      <td>0.332808</td>\n","      <td>1.000000</td>\n","      <td>NaN</td>\n","      <td>0.132030</td>\n","      <td>0.040609</td>\n","      <td>0.674112</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Age</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>SibSp</td>\n","      <td>0.071281</td>\n","      <td>0.128369</td>\n","      <td>0.132030</td>\n","      <td>NaN</td>\n","      <td>1.000000</td>\n","      <td>0.466028</td>\n","      <td>0.345441</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Parch</td>\n","      <td>0.029656</td>\n","      <td>0.136084</td>\n","      <td>0.040609</td>\n","      <td>NaN</td>\n","      <td>0.466028</td>\n","      <td>1.000000</td>\n","      <td>0.329520</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Fare</td>\n","      <td>0.050245</td>\n","      <td>0.298424</td>\n","      <td>0.674112</td>\n","      <td>NaN</td>\n","      <td>0.345441</td>\n","      <td>0.329520</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         index  PassengerId  Survived    Pclass  Age     SibSp     Parch  \\\n","0  PassengerId     1.000000  0.034880  0.053387  NaN  0.071281  0.029656   \n","1     Survived     0.034880  1.000000  0.332808  NaN  0.128369  0.136084   \n","2       Pclass     0.053387  0.332808  1.000000  NaN  0.132030  0.040609   \n","3          Age          NaN       NaN       NaN  NaN       NaN       NaN   \n","4        SibSp     0.071281  0.128369  0.132030  NaN  1.000000  0.466028   \n","5        Parch     0.029656  0.136084  0.040609  NaN  0.466028  1.000000   \n","6         Fare     0.050245  0.298424  0.674112  NaN  0.345441  0.329520   \n","\n","       Fare  \n","0  0.050245  \n","1  0.298424  \n","2  0.674112  \n","3       NaN  \n","4  0.345441  \n","5  0.329520  \n","6  1.000000  "]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["import dcor\n","\n","dicty = {}\n","\n","cont_cols = ['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n","\n","for i in cont_cols:\n","    tlist = []\n","    for j in cont_cols:\n","        tlist.append(dcor.distance_correlation(df[i].values,df[j].values))\n","    dicty[i] = tlist\n","\n","pd.DataFrame(dicty, index = cont_cols).reset_index(drop=False)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:24.069165Z","iopub.status.busy":"2024-08-07T06:50:24.068740Z","iopub.status.idle":"2024-08-07T06:50:25.814183Z","shell.execute_reply":"2024-08-07T06:50:25.812551Z","shell.execute_reply.started":"2024-08-07T06:50:24.069130Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ANOVA Statistic: 1.653526990026601\n","P-value (ANOVA): 0.1988151488242662\n","Kruskal-Wallis Statistic: 1.6509427956425498\n","P-value (Kruskal-Wallis): 0.19883066013561596\n","There is no statistically significant correlation between the categorical Sex and continuous variable PassengerId (ANOVA).\n","There is no statistically significant correlation between the categorical Sex and continuous variable PassengerId (Kruskal-Wallis).\n","\n","ANOVA Statistic: 368.1547321987805\n","P-value (ANOVA): 6.682012140612383e-69\n","Kruskal-Wallis Statistic: 260.4630280282788\n","P-value (Kruskal-Wallis): 1.3601519476400563e-58\n","There is a statistically significant correlation between the categorical Sex and continuous variable Survived (ANOVA).\n","There is a statistically significant correlation between the categorical Sex and continuous variable Survived (Kruskal-Wallis).\n","\n","ANOVA Statistic: 14.713931304103838\n","P-value (ANOVA): 0.00013397596259671712\n","Kruskal-Wallis Statistic: 15.459426411449533\n","P-value (Kruskal-Wallis): 8.429546200531219e-05\n","There is a statistically significant correlation between the categorical Sex and continuous variable Pclass (ANOVA).\n","There is a statistically significant correlation between the categorical Sex and continuous variable Pclass (Kruskal-Wallis).\n","\n","ANOVA Statistic: 7.136579887674061\n","P-value (ANOVA): 0.007691124527749856\n","Kruskal-Wallis Statistic: 4.636922014669144\n","P-value (Kruskal-Wallis): 0.03129107636871361\n","There is a statistically significant correlation between the categorical Sex and continuous variable Age (ANOVA).\n","There is no statistically significant correlation between the categorical Sex and continuous variable Age (Kruskal-Wallis).\n","\n","ANOVA Statistic: 12.171998300864056\n","P-value (ANOVA): 0.0005089911985008323\n","Kruskal-Wallis Statistic: 34.721951654527395\n","P-value (Kruskal-Wallis): 3.803188427087235e-09\n","There is a statistically significant correlation between the categorical Sex and continuous variable SibSp (ANOVA).\n","There is a statistically significant correlation between the categorical Sex and continuous variable SibSp (Kruskal-Wallis).\n","\n","ANOVA Statistic: 57.88376959871613\n","P-value (ANOVA): 7.09394568096233e-14\n","Kruskal-Wallis Statistic: 58.57634688438113\n","P-value (Kruskal-Wallis): 1.9555334609593815e-14\n","There is a statistically significant correlation between the categorical Sex and continuous variable Parch (ANOVA).\n","There is a statistically significant correlation between the categorical Sex and continuous variable Parch (Kruskal-Wallis).\n","\n","ANOVA Statistic: 29.686632121387937\n","P-value (ANOVA): 6.58120020904828e-08\n","Kruskal-Wallis Statistic: 58.281406992294315\n","P-value (Kruskal-Wallis): 2.271810501655658e-14\n","There is a statistically significant correlation between the categorical Sex and continuous variable Fare (ANOVA).\n","There is a statistically significant correlation between the categorical Sex and continuous variable Fare (Kruskal-Wallis).\n","\n","ANOVA Statistic: nan\n","P-value (ANOVA): nan\n","Kruskal-Wallis Statistic: nan\n","P-value (Kruskal-Wallis): nan\n","There is no statistically significant correlation between the categorical Cabin and continuous variable PassengerId (ANOVA).\n","There is no statistically significant correlation between the categorical Cabin and continuous variable PassengerId (Kruskal-Wallis).\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\sonia\\AppData\\Local\\Temp\\ipykernel_13400\\4218089306.py:14: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n","  anova_statistic, p_value_anova = f_oneway(*category_groups)\n","C:\\Users\\sonia\\AppData\\Local\\Temp\\ipykernel_13400\\4218089306.py:20: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n","  kruskal_statistic, p_value_kruskal = kruskal(*category_groups)\n"]},{"name":"stdout","output_type":"stream","text":["ANOVA Statistic: nan\n","P-value (ANOVA): nan\n","Kruskal-Wallis Statistic: nan\n","P-value (Kruskal-Wallis): nan\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Survived (ANOVA).\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Survived (Kruskal-Wallis).\n","\n","ANOVA Statistic: nan\n","P-value (ANOVA): nan\n","Kruskal-Wallis Statistic: nan\n","P-value (Kruskal-Wallis): nan\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Pclass (ANOVA).\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Pclass (Kruskal-Wallis).\n","\n","ANOVA Statistic: nan\n","P-value (ANOVA): nan\n","Kruskal-Wallis Statistic: nan\n","P-value (Kruskal-Wallis): nan\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Age (ANOVA).\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Age (Kruskal-Wallis).\n","\n","ANOVA Statistic: nan\n","P-value (ANOVA): nan\n","Kruskal-Wallis Statistic: nan\n","P-value (Kruskal-Wallis): nan\n","There is no statistically significant correlation between the categorical Cabin and continuous variable SibSp (ANOVA).\n","There is no statistically significant correlation between the categorical Cabin and continuous variable SibSp (Kruskal-Wallis).\n","\n","ANOVA Statistic: nan\n","P-value (ANOVA): nan\n","Kruskal-Wallis Statistic: nan\n","P-value (Kruskal-Wallis): nan\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Parch (ANOVA).\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Parch (Kruskal-Wallis).\n","\n","ANOVA Statistic: nan\n","P-value (ANOVA): nan\n","Kruskal-Wallis Statistic: nan\n","P-value (Kruskal-Wallis): nan\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Fare (ANOVA).\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Fare (Kruskal-Wallis).\n","\n","ANOVA Statistic: 0.5210405505142851\n","P-value (ANOVA): 0.5940841065910331\n","Kruskal-Wallis Statistic: 1.0392594247587112\n","P-value (Kruskal-Wallis): 0.5947407323325824\n","There is no statistically significant correlation between the categorical Embarked and continuous variable PassengerId (ANOVA).\n","There is no statistically significant correlation between the categorical Embarked and continuous variable PassengerId (Kruskal-Wallis).\n","\n","ANOVA Statistic: 13.605270445693582\n","P-value (ANOVA): 1.514339014290716e-06\n","Kruskal-Wallis Statistic: 26.459353270240026\n","P-value (Kruskal-Wallis): 1.796488493944477e-06\n","There is a statistically significant correlation between the categorical Embarked and continuous variable Survived (ANOVA).\n","There is a statistically significant correlation between the categorical Embarked and continuous variable Survived (Kruskal-Wallis).\n","\n","ANOVA Statistic: 46.51218940511203\n","P-value (ANOVA): 6.188928688440989e-20\n","Kruskal-Wallis Statistic: 79.11453719328637\n","P-value (Kruskal-Wallis): 6.614492514568655e-18\n","There is a statistically significant correlation between the categorical Embarked and continuous variable Pclass (ANOVA).\n","There is a statistically significant correlation between the categorical Embarked and continuous variable Pclass (Kruskal-Wallis).\n","\n","ANOVA Statistic: 0.5385246407833076\n","P-value (ANOVA): 0.5837995554014965\n","Kruskal-Wallis Statistic: 0.6476156515790377\n","P-value (Kruskal-Wallis): 0.7233892457801585\n","There is no statistically significant correlation between the categorical Embarked and continuous variable Age (ANOVA).\n","There is no statistically significant correlation between the categorical Embarked and continuous variable Age (Kruskal-Wallis).\n","\n","ANOVA Statistic: 2.1842579946585814\n","P-value (ANOVA): 0.11316698890183281\n","Kruskal-Wallis Statistic: 2.1676648217202406\n","P-value (Kruskal-Wallis): 0.338296546764675\n","There is no statistically significant correlation between the categorical Embarked and continuous variable SibSp (ANOVA).\n","There is no statistically significant correlation between the categorical Embarked and continuous variable SibSp (Kruskal-Wallis).\n","\n","ANOVA Statistic: 3.2267895768620782\n","P-value (ANOVA): 0.040151541423720696\n","Kruskal-Wallis Statistic: 8.87709345670812\n","P-value (Kruskal-Wallis): 0.011813093685278086\n","There is no statistically significant correlation between the categorical Embarked and continuous variable Parch (ANOVA).\n","There is no statistically significant correlation between the categorical Embarked and continuous variable Parch (Kruskal-Wallis).\n","\n","ANOVA Statistic: 38.14030520011266\n","P-value (ANOVA): 1.2896450252631794e-16\n","Kruskal-Wallis Statistic: 74.40439198275804\n","P-value (Kruskal-Wallis): 6.970943556149538e-17\n","There is a statistically significant correlation between the categorical Embarked and continuous variable Fare (ANOVA).\n","There is a statistically significant correlation between the categorical Embarked and continuous variable Fare (Kruskal-Wallis).\n","\n"]}],"source":["import pandas as pd\n","from scipy.stats import f_oneway, kruskal\n","import plotly.express as px\n","\n","cat_cols = [\"Sex\", \"Cabin\", \"Embarked\"]\n","\n","for cat_col in cat_cols:\n","    for var in cont_cols:\n","        # Separate continuous variable by categories\n","        category_groups = [df[df[cat_col] == category][var].fillna(df[var].mean()) for category in df[cat_col].unique()]\n","\n","        # Perform ANOVA test\n","        try:\n","            anova_statistic, p_value_anova = f_oneway(*category_groups)\n","        except:\n","            anova_statistic, p_value_anova = np.nan, np.nan\n","\n","        # Perform Kruskal-Wallis test\n","        try:\n","            kruskal_statistic, p_value_kruskal = kruskal(*category_groups)\n","        except:\n","            kruskal_statistic, p_value_kruskal = np.nan, np.nan\n","\n","        # Print the results for ANOVA\n","        print(\"ANOVA Statistic:\", anova_statistic)\n","        print(\"P-value (ANOVA):\", p_value_anova)\n","\n","        # Print the results for Kruskal-Wallis\n","        print(\"Kruskal-Wallis Statistic:\", kruskal_statistic)\n","        print(\"P-value (Kruskal-Wallis):\", p_value_kruskal)\n","\n","        # Check for significance\n","        alpha = 0.01  # Set your significance level\n","\n","        if p_value_anova < alpha:\n","            print(f\"There is a statistically significant correlation between the categorical {cat_col} and continuous variable {var} (ANOVA).\")\n","        else:\n","            print(f\"There is no statistically significant correlation between the categorical {cat_col} and continuous variable {var} (ANOVA).\")\n","\n","        if p_value_kruskal < alpha:\n","            print(f\"There is a statistically significant correlation between the categorical {cat_col} and continuous variable {var} (Kruskal-Wallis).\")\n","        else:\n","            print(f\"There is no statistically significant correlation between the categorical {cat_col} and continuous variable {var} (Kruskal-Wallis).\")\n","\n","        print()"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:25.816858Z","iopub.status.busy":"2024-08-07T06:50:25.816319Z","iopub.status.idle":"2024-08-07T06:50:25.837463Z","shell.execute_reply":"2024-08-07T06:50:25.835705Z","shell.execute_reply.started":"2024-08-07T06:50:25.816813Z"},"trusted":true},"outputs":[],"source":["df['AgeFill'] = df['Age']\n","\n","df['AgeFill'] = df['AgeFill'].groupby([df['Sex'], df['Pclass']], group_keys=False).apply(lambda x: x.fillna(x.median()))"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:25.839934Z","iopub.status.busy":"2024-08-07T06:50:25.839501Z","iopub.status.idle":"2024-08-07T06:50:25.848732Z","shell.execute_reply":"2024-08-07T06:50:25.846665Z","shell.execute_reply.started":"2024-08-07T06:50:25.839900Z"},"trusted":true},"outputs":[],"source":["def cabin_clean(string):\n","    \n","    string = ''.join(filter(str.isalpha, string))\n","    return \"\".join(set(string)).strip()[0]"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:25.851162Z","iopub.status.busy":"2024-08-07T06:50:25.850676Z","iopub.status.idle":"2024-08-07T06:50:25.878915Z","shell.execute_reply":"2024-08-07T06:50:25.877289Z","shell.execute_reply.started":"2024-08-07T06:50:25.851114Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Cabin\n","m    687\n","C     59\n","B     45\n","D     33\n","E     33\n","A     15\n","F      9\n","G      7\n","T      1\n","Name: count, dtype: int64"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["df['Cabin'] = df['Cabin'].fillna('missing').apply(lambda x : cabin_clean(x))\n","df['Cabin'].value_counts()"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:25.881957Z","iopub.status.busy":"2024-08-07T06:50:25.881381Z","iopub.status.idle":"2024-08-07T06:50:25.994743Z","shell.execute_reply":"2024-08-07T06:50:25.992881Z","shell.execute_reply.started":"2024-08-07T06:50:25.881913Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ANOVA Statistic: 1.22688770063106\n","P-value (ANOVA): 0.2797845287356138\n","Kruskal-Wallis Statistic: 9.805207292067735\n","P-value (Kruskal-Wallis): 0.2789649353699472\n","There is no statistically significant correlation between the categorical Cabin and continuous variable PassengerId (ANOVA).\n","There is no statistically significant correlation between the categorical Cabin and continuous variable PassengerId (Kruskal-Wallis).\n","\n","ANOVA Statistic: 14.102901912348008\n","P-value (ANOVA): 1.9799788951320462e-19\n","Kruskal-Wallis Statistic: 100.91123338123244\n","P-value (Kruskal-Wallis): 2.7800293247009883e-18\n","There is a statistically significant correlation between the categorical Cabin and continuous variable Survived (ANOVA).\n","There is a statistically significant correlation between the categorical Cabin and continuous variable Survived (Kruskal-Wallis).\n","\n","ANOVA Statistic: 153.25741707938195\n","P-value (ANOVA): 5.0195946537424e-161\n","Kruskal-Wallis Statistic: 455.80765531150314\n","P-value (Kruskal-Wallis): 2.1059986867202237e-93\n","There is a statistically significant correlation between the categorical Cabin and continuous variable Pclass (ANOVA).\n","There is a statistically significant correlation between the categorical Cabin and continuous variable Pclass (Kruskal-Wallis).\n","\n","ANOVA Statistic: 10.672878771973101\n","P-value (ANOVA): 2.1549604085985112e-14\n","Kruskal-Wallis Statistic: 66.9035269782369\n","P-value (Kruskal-Wallis): 2.026209407702356e-11\n","There is a statistically significant correlation between the categorical Cabin and continuous variable Age (ANOVA).\n","There is a statistically significant correlation between the categorical Cabin and continuous variable Age (Kruskal-Wallis).\n","\n","ANOVA Statistic: 0.7018807763459586\n","P-value (ANOVA): 0.6901279816793001\n","Kruskal-Wallis Statistic: 13.283957935346429\n","P-value (Kruskal-Wallis): 0.10244582042952047\n","There is no statistically significant correlation between the categorical Cabin and continuous variable SibSp (ANOVA).\n","There is no statistically significant correlation between the categorical Cabin and continuous variable SibSp (Kruskal-Wallis).\n","\n","ANOVA Statistic: 1.094472678872269\n","P-value (ANOVA): 0.3645119734946982\n","Kruskal-Wallis Statistic: 19.59996812680943\n","P-value (Kruskal-Wallis): 0.011960235331578391\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Parch (ANOVA).\n","There is no statistically significant correlation between the categorical Cabin and continuous variable Parch (Kruskal-Wallis).\n","\n","ANOVA Statistic: 54.77098878359365\n","P-value (ANOVA): 3.268300431439393e-72\n","Kruskal-Wallis Statistic: 290.20496372590793\n","P-value (Kruskal-Wallis): 4.996612350448773e-58\n","There is a statistically significant correlation between the categorical Cabin and continuous variable Fare (ANOVA).\n","There is a statistically significant correlation between the categorical Cabin and continuous variable Fare (Kruskal-Wallis).\n","\n"]}],"source":["import pandas as pd\n","from scipy.stats import f_oneway, kruskal\n","import plotly.express as px\n","\n","\n","for cat_col in [\"Cabin\"]:\n","    for var in cont_cols:\n","        # Separate continuous variable by categories\n","        category_groups = [df[df[cat_col] == category][var].fillna(df[var].mean()) for category in df[cat_col].unique()]\n","\n","        # Perform ANOVA test\n","        try:\n","            anova_statistic, p_value_anova = f_oneway(*category_groups)\n","        except:\n","            anova_statistic, p_value_anova = np.nan, np.nan\n","\n","        # Perform Kruskal-Wallis test\n","        try:\n","            kruskal_statistic, p_value_kruskal = kruskal(*category_groups)\n","        except:\n","            kruskal_statistic, p_value_kruskal = np.nan, np.nan\n","\n","        # Print the results for ANOVA\n","        print(\"ANOVA Statistic:\", anova_statistic)\n","        print(\"P-value (ANOVA):\", p_value_anova)\n","\n","        # Print the results for Kruskal-Wallis\n","        print(\"Kruskal-Wallis Statistic:\", kruskal_statistic)\n","        print(\"P-value (Kruskal-Wallis):\", p_value_kruskal)\n","\n","        # Check for significance\n","        alpha = 0.01  # Set your significance level\n","\n","        if p_value_anova < alpha:\n","            print(f\"There is a statistically significant correlation between the categorical {cat_col} and continuous variable {var} (ANOVA).\")\n","        else:\n","            print(f\"There is no statistically significant correlation between the categorical {cat_col} and continuous variable {var} (ANOVA).\")\n","\n","        if p_value_kruskal < alpha:\n","            print(f\"There is a statistically significant correlation between the categorical {cat_col} and continuous variable {var} (Kruskal-Wallis).\")\n","        else:\n","            print(f\"There is no statistically significant correlation between the categorical {cat_col} and continuous variable {var} (Kruskal-Wallis).\")\n","\n","        print()"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:25.997406Z","iopub.status.busy":"2024-08-07T06:50:25.996838Z","iopub.status.idle":"2024-08-07T06:50:26.016169Z","shell.execute_reply":"2024-08-07T06:50:26.014486Z","shell.execute_reply.started":"2024-08-07T06:50:25.997353Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 889 entries, 0 to 888\n","Data columns (total 13 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  889 non-null    int64  \n"," 1   Survived     889 non-null    int64  \n"," 2   Pclass       889 non-null    int64  \n"," 3   Name         889 non-null    object \n"," 4   Sex          889 non-null    object \n"," 5   Age          712 non-null    float64\n"," 6   SibSp        889 non-null    int64  \n"," 7   Parch        889 non-null    int64  \n"," 8   Ticket       889 non-null    object \n"," 9   Fare         889 non-null    float64\n"," 10  Cabin        889 non-null    object \n"," 11  Embarked     889 non-null    object \n"," 12  AgeFill      889 non-null    float64\n","dtypes: float64(3), int64(5), object(5)\n","memory usage: 90.4+ KB\n"]}],"source":["df.info(verbose=True, show_counts=True)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:26.018637Z","iopub.status.busy":"2024-08-07T06:50:26.018067Z","iopub.status.idle":"2024-08-07T06:50:26.111512Z","shell.execute_reply":"2024-08-07T06:50:26.110187Z","shell.execute_reply.started":"2024-08-07T06:50:26.018592Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["corr b/w Sex Sex Cramér's V: 0.9975308847709196\n","corr b/w Sex Cabin Cramér's V: 0.18586211164751676\n","corr b/w Sex Embarked Cramér's V: 0.12256919037251324\n","\n","corr b/w Cabin Sex Cramér's V: 0.18586211164751676\n","corr b/w Cabin Cabin Cramér's V: 1.0\n","corr b/w Cabin Embarked Cramér's V: 0.207205520894203\n","\n","corr b/w Embarked Sex Cramér's V: 0.12256919037251324\n","corr b/w Embarked Cabin Cramér's V: 0.20720552089420302\n","corr b/w Embarked Embarked Cramér's V: 1.0\n","\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from scipy.stats import chi2_contingency\n","\n","for a in cat_cols:\n","    for b in cat_cols:\n","        # Create a contingency table\n","        contingency_table = pd.crosstab(df[a], df[b])\n","\n","        # Perform the Chi-Square test\n","        chi2, p, dof, ex = chi2_contingency(contingency_table)\n","\n","        # Calculate Cramér's V\n","        n = contingency_table.sum().sum()\n","        cramers_v = np.sqrt((chi2 / n) / (min(contingency_table.shape) - 1))\n","\n","        print('corr b/w', a, b, f\"Cramér's V: {cramers_v}\")\n","    print()"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:26.113683Z","iopub.status.busy":"2024-08-07T06:50:26.113174Z","iopub.status.idle":"2024-08-07T06:50:26.124881Z","shell.execute_reply":"2024-08-07T06:50:26.123354Z","shell.execute_reply.started":"2024-08-07T06:50:26.113646Z"},"trusted":true},"outputs":[],"source":["import re\n","\n","def replace_words(string):\n","    string= string.replace(\"CASOTON\", \"CA\").replace(\"SCAHBASLE\", \"SC\").replace(\"SCAH\", \"SC\").replace(\"SCA\", \"SC\").replace(\"SOTONOQ\", \"SOTONO\").replace(\"STONO\", \"SOTONO\").replace(\"SOPP\", \"SOP\").replace(\"FCC\", \"FC\").replace(\"AS 4DIGITS\", \"A 4DIGITS\").replace(\"PPP\", \"PP\")\n","    return string.replace(\"SCBASLE\", \"SC\")\n"," \n","# Function to separate the numbers \n","# and alphabets from the given string\n","def separateNumbersAlphabets(string):\n","    numbers = \"\".join(re.findall(r'[0-9]+', string)).strip()\n","    alphabets = \"\".join(re.findall(r'[a-zA-Z]+', string)).strip()\n","    length_num = str(len(numbers)) + \"DIGITS\"\n","    return alphabets + \" \" + length_num\n","\n","def clean_ticket(string):\n","    string = string.replace(\".\", \"\").replace(\"/\", \"\")\n","    string = separateNumbersAlphabets(string)\n","    string = replace_words(string)\n","    return string.upper()"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:26.127018Z","iopub.status.busy":"2024-08-07T06:50:26.126641Z","iopub.status.idle":"2024-08-07T06:50:26.149826Z","shell.execute_reply":"2024-08-07T06:50:26.148548Z","shell.execute_reply.started":"2024-08-07T06:50:26.126986Z"},"trusted":true},"outputs":[],"source":["df[\"Ticket\"] = df[\"Ticket\"].apply(lambda x : clean_ticket(x))\n","df[\"Ticket1\"] = df[\"Ticket\"].apply(lambda x : x.split(\" \")[0].strip().replace(\"SCBASLE\", \"SC\"))\n","df[\"Ticket2\"] = df[\"Ticket\"].apply(lambda x : x.split(\" \")[1].strip())"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:26.152120Z","iopub.status.busy":"2024-08-07T06:50:26.151666Z","iopub.status.idle":"2024-08-07T06:50:26.719306Z","shell.execute_reply":"2024-08-07T06:50:26.717920Z","shell.execute_reply.started":"2024-08-07T06:50:26.152076Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ANOVA Statistic: 1.0953961376267076\n","P-value (ANOVA): 0.3266642470740986\n","Kruskal-Wallis Statistic: 37.11166299331899\n","P-value (Kruskal-Wallis): 0.32751996325738486\n","There is no statistically significant correlation between the categorical Ticket and continuous variable PassengerId (ANOVA).\n","There is no statistically significant correlation between the categorical Ticket and continuous variable PassengerId (Kruskal-Wallis).\n","\n","ANOVA Statistic: 3.4346081144572818\n","P-value (ANOVA): 3.5820009952437243e-10\n","Kruskal-Wallis Statistic: 106.81930331346328\n","P-value (Kruskal-Wallis): 1.887165204875689e-09\n","There is a statistically significant correlation between the categorical Ticket and continuous variable Survived (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket and continuous variable Survived (Kruskal-Wallis).\n","\n","ANOVA Statistic: 23.12236936731538\n","P-value (ANOVA): 6.120508725876897e-98\n","Kruskal-Wallis Statistic: 423.91239011338183\n","P-value (Kruskal-Wallis): 7.617640587135924e-69\n","There is a statistically significant correlation between the categorical Ticket and continuous variable Pclass (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket and continuous variable Pclass (Kruskal-Wallis).\n","\n","ANOVA Statistic: 2.8108628851396045\n","P-value (ANOVA): 2.794018541167965e-07\n","Kruskal-Wallis Statistic: 84.05566990193694\n","P-value (Kruskal-Wallis): 4.004064329175977e-06\n","There is a statistically significant correlation between the categorical Ticket and continuous variable Age (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket and continuous variable Age (Kruskal-Wallis).\n","\n","ANOVA Statistic: 12.182770287678863\n","P-value (ANOVA): 6.7799463754357e-53\n","Kruskal-Wallis Statistic: 117.29867694264405\n","P-value (Kruskal-Wallis): 4.317911581765691e-11\n","There is a statistically significant correlation between the categorical Ticket and continuous variable SibSp (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket and continuous variable SibSp (Kruskal-Wallis).\n","\n","ANOVA Statistic: 4.265134274847675\n","P-value (ANOVA): 3.261655275854251e-14\n","Kruskal-Wallis Statistic: 124.78963476093057\n","P-value (Kruskal-Wallis): 2.689451885196726e-12\n","There is a statistically significant correlation between the categorical Ticket and continuous variable Parch (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket and continuous variable Parch (Kruskal-Wallis).\n","\n","ANOVA Statistic: 12.144692015115965\n","P-value (ANOVA): 1.0141233231479401e-52\n","Kruskal-Wallis Statistic: 305.42459804902484\n","P-value (Kruskal-Wallis): 2.2230876609395747e-45\n","There is a statistically significant correlation between the categorical Ticket and continuous variable Fare (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket and continuous variable Fare (Kruskal-Wallis).\n","\n","ANOVA Statistic: 0.8393410005030847\n","P-value (ANOVA): 0.6540059139278043\n","Kruskal-Wallis Statistic: 15.162995296486315\n","P-value (Kruskal-Wallis): 0.6507464621468142\n","There is no statistically significant correlation between the categorical Ticket1 and continuous variable PassengerId (ANOVA).\n","There is no statistically significant correlation between the categorical Ticket1 and continuous variable PassengerId (Kruskal-Wallis).\n","\n","ANOVA Statistic: 2.8087809886144623\n","P-value (ANOVA): 8.696825237500854e-05\n","Kruskal-Wallis Statistic: 48.769933565676006\n","P-value (Kruskal-Wallis): 0.00011558040365892111\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable Survived (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable Survived (Kruskal-Wallis).\n","\n","ANOVA Statistic: 15.770399103554055\n","P-value (ANOVA): 2.2070592696656016e-42\n","Kruskal-Wallis Statistic: 206.54962267216064\n","P-value (Kruskal-Wallis): 4.89098362306226e-34\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable Pclass (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable Pclass (Kruskal-Wallis).\n","\n","ANOVA Statistic: 2.141443061182987\n","P-value (ANOVA): 0.0038015473897969223\n","Kruskal-Wallis Statistic: 35.15363078620734\n","P-value (Kruskal-Wallis): 0.009040263415727341\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable Age (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable Age (Kruskal-Wallis).\n","\n","ANOVA Statistic: 7.592245290857348\n","P-value (ANOVA): 1.2301895311463318e-18\n","Kruskal-Wallis Statistic: 53.47125778995051\n","P-value (Kruskal-Wallis): 2.2175929811397822e-05\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable SibSp (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable SibSp (Kruskal-Wallis).\n","\n","ANOVA Statistic: 5.130211524059453\n","P-value (ANOVA): 2.6127665509722805e-11\n","Kruskal-Wallis Statistic: 90.630514173859\n","P-value (Kruskal-Wallis): 1.1124617643950613e-11\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable Parch (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable Parch (Kruskal-Wallis).\n","\n","ANOVA Statistic: 16.63357316178116\n","P-value (ANOVA): 9.001333216999595e-45\n","Kruskal-Wallis Statistic: 202.92055971336973\n","P-value (Kruskal-Wallis): 2.6090869990592686e-33\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable Fare (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket1 and continuous variable Fare (Kruskal-Wallis).\n","\n","ANOVA Statistic: 1.1341985956647684\n","P-value (ANOVA): 0.33914452392951483\n","Kruskal-Wallis Statistic: 7.9268565846596175\n","P-value (Kruskal-Wallis): 0.33908782776024493\n","There is no statistically significant correlation between the categorical Ticket2 and continuous variable PassengerId (ANOVA).\n","There is no statistically significant correlation between the categorical Ticket2 and continuous variable PassengerId (Kruskal-Wallis).\n","\n","ANOVA Statistic: 8.58015507928543\n","P-value (ANOVA): 3.346594250764735e-10\n","Kruskal-Wallis Statistic: 56.67458233211737\n","P-value (Kruskal-Wallis): 6.937456191405019e-10\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable Survived (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable Survived (Kruskal-Wallis).\n","\n","ANOVA Statistic: 64.57281183078314\n","P-value (ANOVA): 4.965851907047897e-75\n","Kruskal-Wallis Statistic: 304.44716307454746\n","P-value (Kruskal-Wallis): 6.790646085810348e-62\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable Pclass (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable Pclass (Kruskal-Wallis).\n","\n","ANOVA Statistic: 8.015058752897948\n","P-value (ANOVA): 1.8349361384510003e-09\n","Kruskal-Wallis Statistic: 47.07312863949993\n","P-value (Kruskal-Wallis): 5.4016513170867225e-08\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable Age (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable Age (Kruskal-Wallis).\n","\n","ANOVA Statistic: 7.737460100917204\n","P-value (ANOVA): 4.22782064104064e-09\n","Kruskal-Wallis Statistic: 37.041101691072555\n","P-value (Kruskal-Wallis): 4.6073160905398705e-06\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable SibSp (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable SibSp (Kruskal-Wallis).\n","\n","ANOVA Statistic: 3.4550725731158853\n","P-value (ANOVA): 0.0011735121906383246\n","Kruskal-Wallis Statistic: 28.59615089290389\n","P-value (Kruskal-Wallis): 0.00017138735889161123\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable Parch (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable Parch (Kruskal-Wallis).\n","\n","ANOVA Statistic: 26.15524547131403\n","P-value (ANOVA): 1.1807691676781116e-32\n","Kruskal-Wallis Statistic: 183.70035528090514\n","P-value (Kruskal-Wallis): 3.220698778707039e-36\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable Fare (ANOVA).\n","There is a statistically significant correlation between the categorical Ticket2 and continuous variable Fare (Kruskal-Wallis).\n","\n"]}],"source":["import pandas as pd\n","from scipy.stats import f_oneway, kruskal\n","import plotly.express as px\n","\n","\n","for cat_col in [\"Ticket\", \"Ticket1\", \"Ticket2\"]:\n","    for var in cont_cols:\n","        # Separate continuous variable by categories\n","        category_groups = [df[df[cat_col] == category][var].fillna(df[var].mean()) for category in df[cat_col].unique()]\n","\n","        # Perform ANOVA test\n","        try:\n","            anova_statistic, p_value_anova = f_oneway(*category_groups)\n","        except:\n","            anova_statistic, p_value_anova = np.nan, np.nan\n","\n","        # Perform Kruskal-Wallis test\n","        try:\n","            kruskal_statistic, p_value_kruskal = kruskal(*category_groups)\n","        except:\n","            kruskal_statistic, p_value_kruskal = np.nan, np.nan\n","\n","        # Print the results for ANOVA\n","        print(\"ANOVA Statistic:\", anova_statistic)\n","        print(\"P-value (ANOVA):\", p_value_anova)\n","\n","        # Print the results for Kruskal-Wallis\n","        print(\"Kruskal-Wallis Statistic:\", kruskal_statistic)\n","        print(\"P-value (Kruskal-Wallis):\", p_value_kruskal)\n","\n","        # Check for significance\n","        alpha = 0.01  # Set your significance level\n","\n","        if p_value_anova < alpha:\n","            print(f\"There is a statistically significant correlation between the categorical {cat_col} and continuous variable {var} (ANOVA).\")\n","        else:\n","            print(f\"There is no statistically significant correlation between the categorical {cat_col} and continuous variable {var} (ANOVA).\")\n","\n","        if p_value_kruskal < alpha:\n","            print(f\"There is a statistically significant correlation between the categorical {cat_col} and continuous variable {var} (Kruskal-Wallis).\")\n","        else:\n","            print(f\"There is no statistically significant correlation between the categorical {cat_col} and continuous variable {var} (Kruskal-Wallis).\")\n","\n","        print()"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:26.721243Z","iopub.status.busy":"2024-08-07T06:50:26.720857Z","iopub.status.idle":"2024-08-07T06:50:26.891819Z","shell.execute_reply":"2024-08-07T06:50:26.890141Z","shell.execute_reply.started":"2024-08-07T06:50:26.721179Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["corr b/w Sex Sex Cramér's V: 0.9975308847709196\n","corr b/w Sex Cabin Cramér's V: 0.18586211164751676\n","corr b/w Sex Embarked Cramér's V: 0.12256919037251324\n","\n","corr b/w Cabin Sex Cramér's V: 0.18586211164751676\n","corr b/w Cabin Cabin Cramér's V: 1.0\n","corr b/w Cabin Embarked Cramér's V: 0.207205520894203\n","\n","corr b/w Embarked Sex Cramér's V: 0.12256919037251324\n","corr b/w Embarked Cabin Cramér's V: 0.20720552089420302\n","corr b/w Embarked Embarked Cramér's V: 1.0\n","\n","corr b/w Ticket Sex Cramér's V: 0.24673963283105924\n","corr b/w Ticket Cabin Cramér's V: 0.26937948386155397\n","corr b/w Ticket Embarked Cramér's V: 0.4902222955949046\n","\n","corr b/w Ticket1 Sex Cramér's V: 0.1976462640600635\n","corr b/w Ticket1 Cabin Cramér's V: 0.2005912107407405\n","corr b/w Ticket1 Embarked Cramér's V: 0.3711233655180238\n","\n","corr b/w Ticket2 Sex Cramér's V: 0.13960575659145275\n","corr b/w Ticket2 Cabin Cramér's V: 0.18361261663451584\n","corr b/w Ticket2 Embarked Cramér's V: 0.3333902630260186\n","\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from scipy.stats import chi2_contingency\n","\n","for a in cat_cols + [\"Ticket\", \"Ticket1\", \"Ticket2\"]:\n","    for b in cat_cols:\n","        # Create a contingency table\n","        contingency_table = pd.crosstab(df[a], df[b])\n","\n","        # Perform the Chi-Square test\n","        chi2, p, dof, ex = chi2_contingency(contingency_table)\n","\n","        # Calculate Cramér's V\n","        n = contingency_table.sum().sum()\n","        cramers_v = np.sqrt((chi2 / n) / (min(contingency_table.shape) - 1))\n","\n","        print('corr b/w', a, b, f\"Cramér's V: {cramers_v}\")\n","    print()"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:26.894154Z","iopub.status.busy":"2024-08-07T06:50:26.893686Z","iopub.status.idle":"2024-08-07T06:50:26.925022Z","shell.execute_reply":"2024-08-07T06:50:26.923004Z","shell.execute_reply.started":"2024-08-07T06:50:26.894113Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","      <th>AgeFill</th>\n","      <th>Ticket1</th>\n","      <th>Ticket2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A 6DIGITS</td>\n","      <td>7.2500</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>22.0</td>\n","      <td>A</td>\n","      <td>6DIGITS</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 5DIGITS</td>\n","      <td>71.2833</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>38.0</td>\n","      <td>PC</td>\n","      <td>5DIGITS</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>SOTONO 8DIGITS</td>\n","      <td>7.9250</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>26.0</td>\n","      <td>SOTONO</td>\n","      <td>8DIGITS</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6DIGITS</td>\n","      <td>53.1000</td>\n","      <td>C</td>\n","      <td>S</td>\n","      <td>35.0</td>\n","      <td></td>\n","      <td>6DIGITS</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6DIGITS</td>\n","      <td>8.0500</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>35.0</td>\n","      <td></td>\n","      <td>6DIGITS</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                  Name     Sex   Age  SibSp  \\\n","0                              Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n","2                               Heikkinen, Miss. Laina  female  26.0      0   \n","3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                             Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch          Ticket     Fare Cabin Embarked  AgeFill Ticket1  Ticket2  \n","0      0       A 6DIGITS   7.2500     m        S     22.0       A  6DIGITS  \n","1      0      PC 5DIGITS  71.2833     C        C     38.0      PC  5DIGITS  \n","2      0  SOTONO 8DIGITS   7.9250     m        S     26.0  SOTONO  8DIGITS  \n","3      0         6DIGITS  53.1000     C        S     35.0          6DIGITS  \n","4      0         6DIGITS   8.0500     m        S     35.0          6DIGITS  "]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:26.927204Z","iopub.status.busy":"2024-08-07T06:50:26.926796Z","iopub.status.idle":"2024-08-07T06:50:26.959688Z","shell.execute_reply":"2024-08-07T06:50:26.957978Z","shell.execute_reply.started":"2024-08-07T06:50:26.927171Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","      <th>AgeFill</th>\n","      <th>Ticket1</th>\n","      <th>Ticket2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A 6DIGITS</td>\n","      <td>7.2500</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>22.0</td>\n","      <td>A</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 5DIGITS</td>\n","      <td>71.2833</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>38.0</td>\n","      <td>PC</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>SOTONO 8DIGITS</td>\n","      <td>7.9250</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>26.0</td>\n","      <td>SOTONO</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6DIGITS</td>\n","      <td>53.1000</td>\n","      <td>C</td>\n","      <td>S</td>\n","      <td>35.0</td>\n","      <td></td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6DIGITS</td>\n","      <td>8.0500</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>35.0</td>\n","      <td></td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                  Name  Sex   Age  SibSp  \\\n","0                              Braund, Mr. Owen Harris    1  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)    0  38.0      1   \n","2                               Heikkinen, Miss. Laina    0  26.0      0   \n","3         Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1   \n","4                             Allen, Mr. William Henry    1  35.0      0   \n","\n","   Parch          Ticket     Fare Cabin Embarked  AgeFill Ticket1  Ticket2  \n","0      0       A 6DIGITS   7.2500     m        S     22.0       A        6  \n","1      0      PC 5DIGITS  71.2833     C        C     38.0      PC        5  \n","2      0  SOTONO 8DIGITS   7.9250     m        S     26.0  SOTONO        8  \n","3      0         6DIGITS  53.1000     C        S     35.0                6  \n","4      0         6DIGITS   8.0500     m        S     35.0                6  "]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["\n","df[\"Sex\"] = df[\"Sex\"].map({\"male\":1, \"female\":0})\n","df[\"Ticket2\"] = df[\"Ticket2\"].apply(lambda x: [int(s) for s in x if s.isdigit()][0])\n","df.head()"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:26.961633Z","iopub.status.busy":"2024-08-07T06:50:26.961237Z","iopub.status.idle":"2024-08-07T06:50:26.977921Z","shell.execute_reply":"2024-08-07T06:50:26.976108Z","shell.execute_reply.started":"2024-08-07T06:50:26.961601Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 889 entries, 0 to 888\n","Data columns (total 15 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  889 non-null    int64  \n"," 1   Survived     889 non-null    int64  \n"," 2   Pclass       889 non-null    int64  \n"," 3   Name         889 non-null    object \n"," 4   Sex          889 non-null    int64  \n"," 5   Age          712 non-null    float64\n"," 6   SibSp        889 non-null    int64  \n"," 7   Parch        889 non-null    int64  \n"," 8   Ticket       889 non-null    object \n"," 9   Fare         889 non-null    float64\n"," 10  Cabin        889 non-null    object \n"," 11  Embarked     889 non-null    object \n"," 12  AgeFill      889 non-null    float64\n"," 13  Ticket1      889 non-null    object \n"," 14  Ticket2      889 non-null    int64  \n","dtypes: float64(3), int64(7), object(5)\n","memory usage: 104.3+ KB\n"]}],"source":["df.info(verbose=True, show_counts=True)"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:26.980806Z","iopub.status.busy":"2024-08-07T06:50:26.980185Z","iopub.status.idle":"2024-08-07T06:50:27.008788Z","shell.execute_reply":"2024-08-07T06:50:27.007534Z","shell.execute_reply.started":"2024-08-07T06:50:26.980763Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>AgeFill</th>\n","      <th>Ticket2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>PassengerId</th>\n","      <td>1.000000</td>\n","      <td>-0.005028</td>\n","      <td>-0.035330</td>\n","      <td>0.043136</td>\n","      <td>0.033681</td>\n","      <td>-0.057686</td>\n","      <td>-0.001657</td>\n","      <td>0.012703</td>\n","      <td>0.036233</td>\n","      <td>-0.039833</td>\n","    </tr>\n","    <tr>\n","      <th>Survived</th>\n","      <td>-0.005028</td>\n","      <td>1.000000</td>\n","      <td>-0.335549</td>\n","      <td>-0.541585</td>\n","      <td>-0.082446</td>\n","      <td>-0.034040</td>\n","      <td>0.083151</td>\n","      <td>0.255290</td>\n","      <td>-0.064411</td>\n","      <td>-0.070176</td>\n","    </tr>\n","    <tr>\n","      <th>Pclass</th>\n","      <td>-0.035330</td>\n","      <td>-0.335549</td>\n","      <td>1.000000</td>\n","      <td>0.127741</td>\n","      <td>-0.365902</td>\n","      <td>0.081656</td>\n","      <td>0.016824</td>\n","      <td>-0.548193</td>\n","      <td>-0.410697</td>\n","      <td>0.088728</td>\n","    </tr>\n","    <tr>\n","      <th>Sex</th>\n","      <td>0.043136</td>\n","      <td>-0.541585</td>\n","      <td>0.127741</td>\n","      <td>1.000000</td>\n","      <td>0.099037</td>\n","      <td>-0.116348</td>\n","      <td>-0.247508</td>\n","      <td>-0.179958</td>\n","      <td>0.108119</td>\n","      <td>0.064239</td>\n","    </tr>\n","    <tr>\n","      <th>Age</th>\n","      <td>0.033681</td>\n","      <td>-0.082446</td>\n","      <td>-0.365902</td>\n","      <td>0.099037</td>\n","      <td>1.000000</td>\n","      <td>-0.307351</td>\n","      <td>-0.187896</td>\n","      <td>0.093143</td>\n","      <td>1.000000</td>\n","      <td>-0.051834</td>\n","    </tr>\n","    <tr>\n","      <th>SibSp</th>\n","      <td>-0.057686</td>\n","      <td>-0.034040</td>\n","      <td>0.081656</td>\n","      <td>-0.116348</td>\n","      <td>-0.307351</td>\n","      <td>1.000000</td>\n","      <td>0.414542</td>\n","      <td>0.160887</td>\n","      <td>-0.249161</td>\n","      <td>-0.089958</td>\n","    </tr>\n","    <tr>\n","      <th>Parch</th>\n","      <td>-0.001657</td>\n","      <td>0.083151</td>\n","      <td>0.016824</td>\n","      <td>-0.247508</td>\n","      <td>-0.187896</td>\n","      <td>0.414542</td>\n","      <td>1.000000</td>\n","      <td>0.217532</td>\n","      <td>-0.174541</td>\n","      <td>-0.078663</td>\n","    </tr>\n","    <tr>\n","      <th>Fare</th>\n","      <td>0.012703</td>\n","      <td>0.255290</td>\n","      <td>-0.548193</td>\n","      <td>-0.179958</td>\n","      <td>0.093143</td>\n","      <td>0.160887</td>\n","      <td>0.217532</td>\n","      <td>1.000000</td>\n","      <td>0.119859</td>\n","      <td>-0.108832</td>\n","    </tr>\n","    <tr>\n","      <th>AgeFill</th>\n","      <td>0.036233</td>\n","      <td>-0.064411</td>\n","      <td>-0.410697</td>\n","      <td>0.108119</td>\n","      <td>1.000000</td>\n","      <td>-0.249161</td>\n","      <td>-0.174541</td>\n","      <td>0.119859</td>\n","      <td>1.000000</td>\n","      <td>-0.034181</td>\n","    </tr>\n","    <tr>\n","      <th>Ticket2</th>\n","      <td>-0.039833</td>\n","      <td>-0.070176</td>\n","      <td>0.088728</td>\n","      <td>0.064239</td>\n","      <td>-0.051834</td>\n","      <td>-0.089958</td>\n","      <td>-0.078663</td>\n","      <td>-0.108832</td>\n","      <td>-0.034181</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             PassengerId  Survived    Pclass       Sex       Age     SibSp  \\\n","PassengerId     1.000000 -0.005028 -0.035330  0.043136  0.033681 -0.057686   \n","Survived       -0.005028  1.000000 -0.335549 -0.541585 -0.082446 -0.034040   \n","Pclass         -0.035330 -0.335549  1.000000  0.127741 -0.365902  0.081656   \n","Sex             0.043136 -0.541585  0.127741  1.000000  0.099037 -0.116348   \n","Age             0.033681 -0.082446 -0.365902  0.099037  1.000000 -0.307351   \n","SibSp          -0.057686 -0.034040  0.081656 -0.116348 -0.307351  1.000000   \n","Parch          -0.001657  0.083151  0.016824 -0.247508 -0.187896  0.414542   \n","Fare            0.012703  0.255290 -0.548193 -0.179958  0.093143  0.160887   \n","AgeFill         0.036233 -0.064411 -0.410697  0.108119  1.000000 -0.249161   \n","Ticket2        -0.039833 -0.070176  0.088728  0.064239 -0.051834 -0.089958   \n","\n","                Parch      Fare   AgeFill   Ticket2  \n","PassengerId -0.001657  0.012703  0.036233 -0.039833  \n","Survived     0.083151  0.255290 -0.064411 -0.070176  \n","Pclass       0.016824 -0.548193 -0.410697  0.088728  \n","Sex         -0.247508 -0.179958  0.108119  0.064239  \n","Age         -0.187896  0.093143  1.000000 -0.051834  \n","SibSp        0.414542  0.160887 -0.249161 -0.089958  \n","Parch        1.000000  0.217532 -0.174541 -0.078663  \n","Fare         0.217532  1.000000  0.119859 -0.108832  \n","AgeFill     -0.174541  0.119859  1.000000 -0.034181  \n","Ticket2     -0.078663 -0.108832 -0.034181  1.000000  "]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["df.corr(numeric_only=True)"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:27.011002Z","iopub.status.busy":"2024-08-07T06:50:27.010521Z","iopub.status.idle":"2024-08-07T06:50:28.162927Z","shell.execute_reply":"2024-08-07T06:50:28.161690Z","shell.execute_reply.started":"2024-08-07T06:50:27.010959Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99       549\n","           1       0.99      0.96      0.98       340\n","\n","    accuracy                           0.98       889\n","   macro avg       0.98      0.98      0.98       889\n","weighted avg       0.98      0.98      0.98       889\n","\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","import sklearn\n","\n","y = df[\"Survived\"]\n","\n","features =  [\"Pclass\", \"Sex\", \"AgeFill\", \"SibSp\", \"Parch\", \"Fare\", \"Ticket2\"]\n","X = df[features]\n","X_test = X\n","\n","model = RandomForestClassifier(n_estimators=100)\n","model.fit(X, y)\n","predictions = model.predict(X_test)\n","\n","print(sklearn.metrics.classification_report(y.values, predictions))"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:44.454172Z","iopub.status.busy":"2024-08-07T06:50:44.453612Z","iopub.status.idle":"2024-08-07T06:50:46.623005Z","shell.execute_reply":"2024-08-07T06:50:46.621437Z","shell.execute_reply.started":"2024-08-07T06:50:44.454121Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.cluster import KMeans\n","# import hdbscan\n","from sklearn.metrics import silhouette_score\n","from sklearn.model_selection import ParameterGrid\n","from sklearn.preprocessing import StandardScaler\n","import random\n","random.seed(48)\n","\n","\n","\n","def get_clusters(df, final_cols):\n","    \n","    to_drop = []\n","    req_cols = final_cols + [\"Survived\"] #sorted(set(df.columns) - set(to_drop))\n","    X = df[req_cols]\n","    Xstd = X.values\n","\n","    # Define parameter grid for HDBSCAN\n","    param_grid = {\n","      'min_cluster_size': list(range(2,20))\n","      #'min_samples': [1, 2, 3]\n","    }\n","\n","    best_score = -1\n","    best_params = None\n","\n","  # Iterate over parameter grid\n","    for params in ParameterGrid(param_grid):\n","        model = hdbscan.HDBSCAN(**params, gen_min_span_tree=True)\n","        cluster_labels = model.fit_predict(Xstd)\n","        unique_labels = np.unique(cluster_labels)\n","        if len(unique_labels) > 1:  # Check if more than one cluster is formed\n","            silhouette_avg = silhouette_score(Xstd, cluster_labels) if len(unique_labels) > 1 else -1\n","            if silhouette_avg > best_score:\n","                best_score = silhouette_avg\n","                best_params = params\n","\n","    if best_params is not None:\n","        print(best_params)\n","        best_model = hdbscan.HDBSCAN(**best_params, gen_min_span_tree=True)\n","        cluster_labels = best_model.fit_predict(Xstd)\n","        df[\"cluster_\"] = [str(i) for i in cluster_labels]\n","    else:\n","        print(\"HDBSCAN produced only one cluster label. Unable to split the data.\")\n","        df[\"cluster_\"] = \"0\"\n","\n","    return df\n","\n","# final_cols = [\"Pclass\", \"Sex\", \"AgeFill\", \"SibSp\", \"Parch\", \"Fare\", \"Ticket2\"]\n","\n","# df = get_clusters(df, final_cols)"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","      <th>AgeFill</th>\n","      <th>Ticket1</th>\n","      <th>Ticket2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A 6DIGITS</td>\n","      <td>7.2500</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>22.0</td>\n","      <td>A</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 5DIGITS</td>\n","      <td>71.2833</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>38.0</td>\n","      <td>PC</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>SOTONO 8DIGITS</td>\n","      <td>7.9250</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>26.0</td>\n","      <td>SOTONO</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6DIGITS</td>\n","      <td>53.1000</td>\n","      <td>C</td>\n","      <td>S</td>\n","      <td>35.0</td>\n","      <td></td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6DIGITS</td>\n","      <td>8.0500</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>35.0</td>\n","      <td></td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                  Name  Sex   Age  SibSp  \\\n","0                              Braund, Mr. Owen Harris    1  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)    0  38.0      1   \n","2                               Heikkinen, Miss. Laina    0  26.0      0   \n","3         Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1   \n","4                             Allen, Mr. William Henry    1  35.0      0   \n","\n","   Parch          Ticket     Fare Cabin Embarked  AgeFill Ticket1  Ticket2  \n","0      0       A 6DIGITS   7.2500     m        S     22.0       A        6  \n","1      0      PC 5DIGITS  71.2833     C        C     38.0      PC        5  \n","2      0  SOTONO 8DIGITS   7.9250     m        S     26.0  SOTONO        8  \n","3      0         6DIGITS  53.1000     C        S     35.0                6  \n","4      0         6DIGITS   8.0500     m        S     35.0                6  "]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/plain":["cluster_\n","-1      308\n"," 89      17\n"," 66      16\n"," 127     16\n"," 128     12\n"," 19      12\n"," 116     10\n"," 28       9\n"," 13       9\n"," 53       9\n"," 79       9\n"," 49       9\n"," 43       8\n"," 104      8\n"," 31       8\n"," 124      7\n"," 15       7\n"," 83       7\n"," 36       7\n"," 25       6\n"," 44       6\n"," 86       6\n"," 121      6\n"," 1        6\n"," 29       6\n"," 54       6\n"," 14       6\n"," 107      6\n"," 4        6\n"," 100      6\n"," 30       5\n"," 109      5\n"," 81       5\n"," 125      5\n"," 38       5\n"," 17       5\n"," 48       5\n"," 56       5\n"," 22       5\n"," 11       5\n"," 122      5\n"," 42       5\n"," 51       5\n"," 23       5\n"," 90       5\n"," 114      5\n"," 112      5\n"," 18       5\n"," 115      5\n"," 78       5\n"," 95       4\n"," 84       4\n"," 71       4\n"," 77       4\n"," 26       4\n"," 9        4\n"," 103      4\n"," 118      4\n"," 27       4\n"," 37       4\n"," 105      4\n"," 70       4\n"," 123      4\n"," 6        4\n"," 76       4\n"," 75       4\n"," 58       4\n"," 8        4\n"," 87       4\n"," 3        4\n"," 120      4\n"," 73       4\n"," 64       3\n"," 101      3\n"," 97       3\n"," 102      3\n"," 91       3\n"," 55       3\n"," 33       3\n"," 5        3\n"," 111      3\n"," 72       3\n"," 113      3\n"," 98       3\n"," 65       3\n"," 59       3\n"," 126      3\n"," 62       3\n"," 45       3\n"," 94       3\n"," 68       3\n"," 47       3\n"," 12       3\n"," 0        3\n"," 117      3\n"," 10       3\n"," 35       3\n"," 39       3\n"," 7        3\n"," 106      3\n"," 119      3\n"," 60       3\n"," 24       3\n"," 41       2\n"," 20       2\n"," 80       2\n"," 32       2\n"," 110      2\n"," 74       2\n"," 93       2\n"," 82       2\n"," 61       2\n"," 46       2\n"," 57       2\n"," 67       2\n"," 108      2\n"," 92       2\n"," 34       2\n"," 16       2\n"," 88       2\n"," 69       2\n"," 52       2\n"," 85       2\n"," 99       2\n"," 50       2\n"," 63       2\n"," 40       2\n"," 96       2\n"," 2        2\n"," 21       2\n","Name: count, dtype: int64"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["clust_df = pd.read_csv(r\"cluster_.csv\")\n","df[\"cluster_\"] = df[\"PassengerId\"].map(dict(zip(clust_df[\"PassengerId\"], clust_df[\"cluster_\"])))\n","df[\"cluster_\"].value_counts()"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:46.626161Z","iopub.status.busy":"2024-08-07T06:50:46.624970Z","iopub.status.idle":"2024-08-07T06:50:46.981092Z","shell.execute_reply":"2024-08-07T06:50:46.979600Z","shell.execute_reply.started":"2024-08-07T06:50:46.626115Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Assuming df is your DataFrame, \"cluster_\" is the column with cluster labels,\n","unique_clusters = df[\"cluster_\"].unique()\n","\n","train_indices = []\n","val_indices = []\n","test_indices = []\n","\n","stratify_=True\n","\n","for cluster in unique_clusters:\n","    cluster_data = df[df[\"cluster_\"] == cluster]\n","    cluster_indices = cluster_data.index.values\n","    cluster_y = cluster_data['Survived'].values\n","\n","    if stratify_ == True: #if you have categorical target variable\n","        \n","        \n","        # Split the data into a training set and a combined testing/validation set\n","        try:\n","            train_idx, temp_idx, _, temp_y = train_test_split(cluster_indices, cluster_y, test_size=0.4, stratify=cluster_y, random_state=42)\n","        except:\n","            try:\n","                train_idx, temp_idx, _, temp_y = train_test_split(cluster_indices, cluster_y, test_size=0.4,  random_state=42)\n","            except:\n","                #train, X_test_val, y_train, y_test_val = _X_, pd.DataFrame(columns=_X_.columns), _y_, pd.DataFrame(columns=[cat_var])\n","                train_idx, temp_idx, _, temp_y = [0], [0], 0, [0]\n","\n","        # Further split the combined testing/validation set into equal-sized test and validation sets\n","        try:\n","            val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=temp_y, random_state=42)\n","        except:\n","            try:\n","                #test, val, y_test, y_val = X_test_val, pd.DataFrame(columns=X_test_val.columns), y_test_val, pd.DataFrame(columns=[cat_var])\n","                val_idx, test_idx = [], temp_idx\n","            except:\n","                val_idx, test_idx = [], []\n","        \n","    else:\n","        # Split indices of the current cluster into train and temp (which will be further split into val and test)\n","        train_idx, temp_idx = train_test_split(cluster_indices, test_size=0.4, random_state=42)\n","        val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n","    \n","    \n","    train_indices.extend(train_idx)\n","    val_indices.extend(val_idx)\n","    test_indices.extend(test_idx)\n","\n","# Convert the indices lists to numpy arrays\n","train_indices = np.array(train_indices)\n","val_indices = np.array(val_indices)\n","test_indices = np.array(test_indices)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","      <th>AgeFill</th>\n","      <th>Ticket1</th>\n","      <th>Ticket2</th>\n","      <th>cluster_</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A 6DIGITS</td>\n","      <td>7.2500</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>22.0</td>\n","      <td>A</td>\n","      <td>6</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 5DIGITS</td>\n","      <td>71.2833</td>\n","      <td>C</td>\n","      <td>C</td>\n","      <td>38.0</td>\n","      <td>PC</td>\n","      <td>5</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>SOTONO 8DIGITS</td>\n","      <td>7.9250</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>26.0</td>\n","      <td>SOTONO</td>\n","      <td>8</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6DIGITS</td>\n","      <td>53.1000</td>\n","      <td>C</td>\n","      <td>S</td>\n","      <td>35.0</td>\n","      <td></td>\n","      <td>6</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6DIGITS</td>\n","      <td>8.0500</td>\n","      <td>m</td>\n","      <td>S</td>\n","      <td>35.0</td>\n","      <td></td>\n","      <td>6</td>\n","      <td>98</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                  Name  Sex   Age  SibSp  \\\n","0                              Braund, Mr. Owen Harris    1  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)    0  38.0      1   \n","2                               Heikkinen, Miss. Laina    0  26.0      0   \n","3         Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1   \n","4                             Allen, Mr. William Henry    1  35.0      0   \n","\n","   Parch          Ticket     Fare Cabin Embarked  AgeFill Ticket1  Ticket2  \\\n","0      0       A 6DIGITS   7.2500     m        S     22.0       A        6   \n","1      0      PC 5DIGITS  71.2833     C        C     38.0      PC        5   \n","2      0  SOTONO 8DIGITS   7.9250     m        S     26.0  SOTONO        8   \n","3      0         6DIGITS  53.1000     C        S     35.0                6   \n","4      0         6DIGITS   8.0500     m        S     35.0                6   \n","\n","   cluster_  \n","0        -1  \n","1        -1  \n","2        -1  \n","3        28  \n","4        98  "]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:46.983371Z","iopub.status.busy":"2024-08-07T06:50:46.982933Z","iopub.status.idle":"2024-08-07T06:50:46.996190Z","shell.execute_reply":"2024-08-07T06:50:46.994503Z","shell.execute_reply.started":"2024-08-07T06:50:46.983332Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(480, 7)\n","(145, 7)\n","(264, 7)\n","(480,)\n","(145,)\n","(264,)\n"]}],"source":["# Assuming 'X' are the features and 'y' is the target column\n","\n","final_cols = [\"Pclass\", \"Sex\", \"AgeFill\", \"SibSp\", \"Parch\", \"Fare\", \"Ticket2\"]\n","\n","X = df[final_cols].values\n","y = df['Survived'].values\n","\n","# Select the corresponding data for train, validation, and test sets\n","X_train, y_train = X[train_indices], y[train_indices]\n","X_val, y_val = X[val_indices], y[val_indices]\n","X_test, y_test = X[test_indices], y[test_indices]\n","\n","for i in [X_train,\n","        X_val,\n","        X_test,\n","        y_train,\n","        y_val,\n","        y_test]:\n","  print(i.shape)"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:46.999125Z","iopub.status.busy":"2024-08-07T06:50:46.998511Z","iopub.status.idle":"2024-08-07T06:50:47.349678Z","shell.execute_reply":"2024-08-07T06:50:47.348219Z","shell.execute_reply.started":"2024-08-07T06:50:46.999074Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.81      0.88      0.84       157\n","           1       0.80      0.70      0.75       107\n","\n","    accuracy                           0.81       264\n","   macro avg       0.80      0.79      0.80       264\n","weighted avg       0.81      0.81      0.80       264\n","\n","0.7899577355794988\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","import sklearn\n","\n","\n","model = RandomForestClassifier(random_state = 42)\n","model.fit(X_train, y_train)\n","predictions = model.predict(X_test)\n","\n","print(sklearn.metrics.classification_report(y_test, predictions))\n","print(sklearn.metrics.roc_auc_score(y_test, predictions))"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.353125Z","iopub.status.busy":"2024-08-07T06:50:47.351905Z","iopub.status.idle":"2024-08-07T06:50:47.378346Z","shell.execute_reply":"2024-08-07T06:50:47.377243Z","shell.execute_reply.started":"2024-08-07T06:50:47.353073Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.85      0.82      0.84        96\n","           1       0.67      0.71      0.69        49\n","\n","    accuracy                           0.79       145\n","   macro avg       0.76      0.77      0.76       145\n","weighted avg       0.79      0.79      0.79       145\n","\n","0.7686011904761906\n"]}],"source":["predictions = model.predict(X_val)\n","\n","print(sklearn.metrics.classification_report(y_val, predictions))\n","print(sklearn.metrics.roc_auc_score(y_val, predictions))"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.380414Z","iopub.status.busy":"2024-08-07T06:50:47.380024Z","iopub.status.idle":"2024-08-07T06:50:47.387456Z","shell.execute_reply":"2024-08-07T06:50:47.386029Z","shell.execute_reply.started":"2024-08-07T06:50:47.380380Z"},"trusted":true},"outputs":[],"source":["# from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.model_selection import GridSearchCV\n","\n","# # Define the model\n","# rf = RandomForestClassifier(random_state = 42)\n","\n","# # Define the parameter grid\n","# param_grid = {\n","#     'n_estimators': [50, 100, 200],\n","#     'max_features': ['auto'],\n","#     'max_depth': [None],\n","#     'min_samples_split': [2, 5, 10],\n","#     'min_samples_leaf': [1, 2, 4],\n","#     'bootstrap': [True]\n","# }\n","\n","# # Setup the grid search\n","# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n","#                            cv=5, n_jobs=-1, verbose=2, scoring='roc_auc')\n","\n","# # Fit the grid search\n","# grid_search.fit(X_train, y_train)\n","\n","# # Print the best parameters\n","# print(f\"Best parameters: {grid_search.best_params_}\")\n","# print(f\"Best score: {grid_search.best_score_}\")"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.389663Z","iopub.status.busy":"2024-08-07T06:50:47.389215Z","iopub.status.idle":"2024-08-07T06:50:47.406098Z","shell.execute_reply":"2024-08-07T06:50:47.404629Z","shell.execute_reply.started":"2024-08-07T06:50:47.389626Z"},"trusted":true},"outputs":[],"source":["\n","\n","def preprocess(df):\n","    df['AgeFill'] = df['Age']\n","    df['AgeFill'] = df['AgeFill'].groupby([df['Sex'], df['Pclass']], group_keys=False).apply(lambda x: x.fillna(x.median()))\n","    \n","    df['Cabin'] = df['Cabin'].fillna('missing').apply(lambda x : cabin_clean(x))\n","    \n","\n","    df[\"Ticket\"] = df[\"Ticket\"].apply(lambda x : clean_ticket(x))\n","    df[\"Ticket1\"] = df[\"Ticket\"].apply(lambda x : x.split(\" \")[0].strip().replace(\"SCBASLE\", \"SC\"))\n","    df[\"Ticket2\"] = df[\"Ticket\"].apply(lambda x : x.split(\" \")[1].strip())\n","    \n","    df['Fare'] = df['Fare'].groupby([df['Sex'], df['Pclass'], df['Ticket']], group_keys=False).apply(lambda x: x.fillna(x.mean()))\n","    \n","    df[\"Sex\"] = df[\"Sex\"].map({\"male\":1, \"female\":0})\n","    df[\"Ticket2\"] = df[\"Ticket2\"].apply(lambda x: [int(s) for s in x if s.isdigit()][0])\n","    \n","    return df"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.408586Z","iopub.status.busy":"2024-08-07T06:50:47.408077Z","iopub.status.idle":"2024-08-07T06:50:47.444843Z","shell.execute_reply":"2024-08-07T06:50:47.443523Z","shell.execute_reply.started":"2024-08-07T06:50:47.408541Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 418 entries, 0 to 417\n","Data columns (total 11 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  418 non-null    int64  \n"," 1   Pclass       418 non-null    int64  \n"," 2   Name         418 non-null    object \n"," 3   Sex          418 non-null    object \n"," 4   Age          332 non-null    float64\n"," 5   SibSp        418 non-null    int64  \n"," 6   Parch        418 non-null    int64  \n"," 7   Ticket       418 non-null    object \n"," 8   Fare         417 non-null    float64\n"," 9   Cabin        91 non-null     object \n"," 10  Embarked     418 non-null    object \n","dtypes: float64(2), int64(4), object(5)\n","memory usage: 36.1+ KB\n"]}],"source":["test = pd.read_csv(\"test.csv\")\n","test.info(verbose=True, show_counts=True)"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.447714Z","iopub.status.busy":"2024-08-07T06:50:47.447093Z","iopub.status.idle":"2024-08-07T06:50:47.493605Z","shell.execute_reply":"2024-08-07T06:50:47.492321Z","shell.execute_reply.started":"2024-08-07T06:50:47.447662Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 418 entries, 0 to 417\n","Data columns (total 14 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  418 non-null    int64  \n"," 1   Pclass       418 non-null    int64  \n"," 2   Name         418 non-null    object \n"," 3   Sex          418 non-null    int64  \n"," 4   Age          332 non-null    float64\n"," 5   SibSp        418 non-null    int64  \n"," 6   Parch        418 non-null    int64  \n"," 7   Ticket       418 non-null    object \n"," 8   Fare         418 non-null    float64\n"," 9   Cabin        418 non-null    object \n"," 10  Embarked     418 non-null    object \n"," 11  AgeFill      418 non-null    float64\n"," 12  Ticket1      418 non-null    object \n"," 13  Ticket2      418 non-null    int64  \n","dtypes: float64(3), int64(6), object(5)\n","memory usage: 45.8+ KB\n"]}],"source":["test = preprocess(test)\n","test.info(verbose=True, show_counts=True)"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.502485Z","iopub.status.busy":"2024-08-07T06:50:47.501955Z","iopub.status.idle":"2024-08-07T06:50:47.514559Z","shell.execute_reply":"2024-08-07T06:50:47.512941Z","shell.execute_reply.started":"2024-08-07T06:50:47.502415Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(418, 7)"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["final_cols = [\"Pclass\", \"Sex\", \"AgeFill\", \"SibSp\", \"Parch\", \"Fare\", \"Ticket2\"]\n","\n","X_test = test[final_cols].values\n","X_test.shape"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.516766Z","iopub.status.busy":"2024-08-07T06:50:47.516291Z","iopub.status.idle":"2024-08-07T06:50:47.540303Z","shell.execute_reply":"2024-08-07T06:50:47.538538Z","shell.execute_reply.started":"2024-08-07T06:50:47.516732Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>AgeFill</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Ticket2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>34.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.8292</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>47.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.0000</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>62.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9.6875</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.6625</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12.2875</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Pclass  Sex  AgeFill  SibSp  Parch     Fare  Ticket2\n","0       3    1     34.5      0      0   7.8292        6\n","1       3    0     47.0      1      0   7.0000        6\n","2       2    1     62.0      0      0   9.6875        6\n","3       3    1     27.0      0      0   8.6625        6\n","4       3    0     22.0      1      1  12.2875        7"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["test[final_cols].head()"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.542891Z","iopub.status.busy":"2024-08-07T06:50:47.542332Z","iopub.status.idle":"2024-08-07T06:50:47.889499Z","shell.execute_reply":"2024-08-07T06:50:47.887930Z","shell.execute_reply.started":"2024-08-07T06:50:47.542853Z"},"trusted":true},"outputs":[{"data":{"text/plain":["418"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["model = RandomForestClassifier(random_state = 42)\n","model.fit(X, y)\n","predictions = model.predict(X_test)\n","\n","test[\"Survived\"] = predictions\n","len(predictions)"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.892132Z","iopub.status.busy":"2024-08-07T06:50:47.891246Z","iopub.status.idle":"2024-08-07T06:50:47.905997Z","shell.execute_reply":"2024-08-07T06:50:47.904393Z","shell.execute_reply.started":"2024-08-07T06:50:47.892089Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>892</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>893</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>894</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>895</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>896</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived\n","0          892         0\n","1          893         0\n","2          894         0\n","3          895         1\n","4          896         1"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["test[[\"PassengerId\", \"Survived\"]].head()"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.909198Z","iopub.status.busy":"2024-08-07T06:50:47.908225Z","iopub.status.idle":"2024-08-07T06:50:47.931679Z","shell.execute_reply":"2024-08-07T06:50:47.929574Z","shell.execute_reply.started":"2024-08-07T06:50:47.909138Z"},"trusted":true},"outputs":[],"source":["test[[\"PassengerId\", \"Survived\"]].to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.934089Z","iopub.status.busy":"2024-08-07T06:50:47.933643Z","iopub.status.idle":"2024-08-07T06:50:47.951292Z","shell.execute_reply":"2024-08-07T06:50:47.949918Z","shell.execute_reply.started":"2024-08-07T06:50:47.934053Z"},"trusted":true},"outputs":[],"source":["# # import the modules we'll need\n","# from IPython.display import HTML\n","# import pandas as pd\n","# import numpy as np\n","# import base64\n","\n","# def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n","#     csv = df.to_csv(index=False)\n","#     b64 = base64.b64encode(csv.encode())\n","#     payload = b64.decode()\n","#     html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n","#     html = html.format(payload=payload,title=title,filename=filename)\n","#     return HTML(html)\n","\n","\n","# # create a link to download the dataframe\n","# create_download_link(test[[\"PassengerId\", \"Survived\"]])"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:47.954149Z","iopub.status.busy":"2024-08-07T06:50:47.953493Z","iopub.status.idle":"2024-08-07T06:50:48.050210Z","shell.execute_reply":"2024-08-07T06:50:48.048847Z","shell.execute_reply.started":"2024-08-07T06:50:47.954097Z"},"trusted":true},"outputs":[],"source":["# import joblib\n","# joblib.dump(model, 'titanic_model.pkl')\n","# model = joblib.load('titanic_model.pkl')"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:50:49.236844Z","iopub.status.busy":"2024-08-07T06:50:49.235218Z","iopub.status.idle":"2024-08-07T06:50:49.246700Z","shell.execute_reply":"2024-08-07T06:50:49.244893Z","shell.execute_reply.started":"2024-08-07T06:50:49.236778Z"},"trusted":true},"outputs":[],"source":["# from IPython.display import FileLink\n","# FileLink(r'titanic_model.pkl')"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:55:58.815112Z","iopub.status.busy":"2024-08-07T06:55:58.814623Z","iopub.status.idle":"2024-08-07T06:56:00.201862Z","shell.execute_reply":"2024-08-07T06:56:00.200451Z","shell.execute_reply.started":"2024-08-07T06:55:58.815078Z"},"trusted":true},"outputs":[],"source":["import gzip, pickle, pickletools\n","filepath = \"titanic_model.pkl\"\n","with gzip.open(filepath, \"wb\") as f:\n","    pickled = pickle.dumps(model)\n","    f.write(pickled)"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:57:12.487212Z","iopub.status.busy":"2024-08-07T06:57:12.486546Z","iopub.status.idle":"2024-08-07T06:57:12.518976Z","shell.execute_reply":"2024-08-07T06:57:12.517584Z","shell.execute_reply.started":"2024-08-07T06:57:12.487166Z"},"trusted":true},"outputs":[],"source":["with gzip.open(filepath, 'rb') as f:\n","    p = pickle.Unpickler(f)\n","    model = p.load()"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T06:57:21.304968Z","iopub.status.busy":"2024-08-07T06:57:21.304463Z","iopub.status.idle":"2024-08-07T06:57:21.319271Z","shell.execute_reply":"2024-08-07T06:57:21.317823Z","shell.execute_reply.started":"2024-08-07T06:57:21.304933Z"},"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-1 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-1 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-1 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-1 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-1 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-1 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-1 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-1 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-1 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-1 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-1 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-1 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-1 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-1 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-1 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-1 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"],"text/plain":["RandomForestClassifier(random_state=42)"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:50:49.886303Z","iopub.status.idle":"2024-08-07T06:50:49.886893Z","shell.execute_reply":"2024-08-07T06:50:49.886676Z","shell.execute_reply.started":"2024-08-07T06:50:49.886654Z"},"trusted":true},"outputs":[],"source":["# !pip freeze"]},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Imported packages: ['re', 'pandas', 'scipy', 'plotly', 'sklearn', 'nbconvert', 'xgboost', 'random', 'gzip', 'dcor', 'nbformat', 'numpy']\n"]}],"source":["import re\n","import nbformat\n","\n","def extract_imported_packages_from_notebook(notebook_path):\n","    with open(notebook_path, 'r') as file:\n","        notebook = nbformat.read(file, as_version=4)\n","\n","    imported_packages = set()\n","    import_re = re.compile(r'^\\s*import\\s+([^\\s]+)', re.MULTILINE)\n","    from_import_re = re.compile(r'^\\s*from\\s+([^\\s]+)', re.MULTILINE)\n","\n","    for cell in notebook.cells:\n","        if cell.cell_type == 'code':\n","            cell_text = cell.source\n","\n","            for match in import_re.finditer(cell_text):\n","                package = match.group(1).split('.')[0]\n","                imported_packages.add(package)\n","\n","            for match in from_import_re.finditer(cell_text):\n","                package = match.group(1).split('.')[0]\n","                imported_packages.add(package)\n","\n","    return imported_packages\n","\n","# Path to your Jupyter notebook\n","notebook_file_path = r'C:\\Users\\sonia\\Downloads\\Extra\\titanic\\titanic_notebook.ipynb'  # Replace with your notebook file path\n","\n","# Extract the imported packages\n","imported_packages = extract_imported_packages_from_notebook(notebook_file_path)\n","imported_packages = [i.replace(\",\", \"\") for i in imported_packages]\n","\n","# Print the imported packages\n","print(\"Imported packages:\", imported_packages)"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["requirements.txt has been generated.\n","['Flask', 'pandas', 'scipy', 'plotly', 'nbconvert', 'xgboost', 'dcor', 'scikit_learn', 'nbformat', 'numpy']\n"]}],"source":["import subprocess\n","import os\n","\n","def generate_requirements_file(directory):\n","    try:\n","        # Run `pipreqs` command to generate requirements.txt\n","        subprocess.run(['pipreqs', '--force', '--ignore', 'tests', directory], check=True)\n","        print(\"requirements.txt has been generated.\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"Error occurred while running pipreqs: {e}\")\n","\n","def get_package_names_from_requirements():\n","    requirements_file = 'requirements.txt'\n","    package_names = set()\n","    \n","    if os.path.exists(requirements_file):\n","        try:\n","            with open(requirements_file, 'r') as file:\n","                lines = file.readlines()\n","                for line in lines:\n","                    if '==' in line:\n","                        name, _ = line.strip().split('==')\n","                        package_names.add(name)\n","        except IOError as e:\n","            print(f\"Error reading {requirements_file}: {e}\")\n","    else:\n","        print(f\"{requirements_file} does not exist.\")\n","    \n","    return package_names\n","\n","# Example usage\n","project_directory = '.'  # Replace with your project directory\n","generate_requirements_file(project_directory)\n","installed_package_names = list(get_package_names_from_requirements())\n","print(installed_package_names)"]},{"cell_type":"code","execution_count":159,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["pandas 2.2.2\n","scipy 1.14.0\n","plotly 5.23.0\n","xgboost 2.1.1\n","nbformat 5.10.4\n","dcor 0.6\n","scikit_learn 1.5.1\n","nbconvert 7.16.4\n","numpy 2.0.1\n"]},{"data":{"text/plain":["{'gzip', 'random', 're', 'sklearn'}"]},"execution_count":159,"metadata":{},"output_type":"execute_result"}],"source":["from importlib.metadata import version\n","no_match = []\n","for i in set(installed_package_names + imported_packages):\n","    try:\n","        print(i, version(i))\n","    except:\n","        no_match.append(i)\n","\n","final_no_match = set(no_match) - set(installed_package_names).intersection(set(no_match))\n","final_no_match"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5477725,"sourceId":9079712,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
